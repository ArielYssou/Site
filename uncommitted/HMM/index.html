<!DOCTYPE html>
<html lang='en'>
	<head>

		<meta charset="utf-8">
		<meta name="viewport" content="width=device-width, intial-scale=1">

		<!-- Name on tab -->
		<title>HMM</title>

		<!-- Google Fonts -->
		<link href="https://fonts.googleapis.com/css?family=Cormorant+Garamond:400,700&display=swap" rel="stylesheet"> 

		<!-- Custom CSS -->
		<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
		<link rel="stylesheet" href="../../css/notebook.css"> <!--TARGET-->
		<link rel="stylesheet" href="../../css/pygments.css"> <!--TARGET-->
		<link rel="stylesheet" href="../../css/style.css"> <!--TARGET-->

		<script src="https://cdn.jsdelivr.net/npm/p5@0.10.2/lib/p5.js"></script>

		<!-- Custom p5js animations -->
		<script src="sketch.js"></script>

    <!-- mathjax -->
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script>
      MathJax = {
        tex: {
          inlineMath: [['$', '$'], ['\\(', '\\)']]
        },
        svg: {
          fontCache: 'global'
        }
      };
    </script>

	</head>

	<body>
		<!-- Navigation bar -->
		<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top">
			<a class="navbar-brand" href="../.." style="font-weight:bold;">Ariel Yssou</a> <!--TARGET-->
			<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
				<span class="navbar-toggler-icon"></span>
			</button>
			<div class="collapse navbar-collapse" id="navbarSupportedContent">
				<ul class="navbar-nav mr-auto">
					<li class="nav-item">
						<a class="nav-link" href="../.." style="font-weight:bold;">Home</a><!--TARGET-->
 
					</li>
					<li class="nav-item active">
						<a class="nav-link" href="../../blog" style="font-weight:bold;">Blog <span class="sr-only">(current)</span></a><!--TARGET-->
					</li>
					<li class="nav-item">
						<a class="nav-link" href="../../about" style="font-weight:bold;">About</a><!--TARGET-->
					</li>
				</ul>
			</div>
			<div class="collapse navbar-collapse" id="navbarSupportedContent">
				<ul class="navbar-nav ml-auto">
					<li class="nav-item">
						<a class="nav-link text-nowrap" href="https://github.com/ArielYssou" target="_blank"><i class="fab fa-github fa-lg"></i></a>
					</li>
					<li class="nav-item">
						<a class="nav-link text-nowrap" href="https://www.linkedin.com/in/ariel-yssou-oliveira-f-2a07a5b5/" target="_blank"><i class="fab fa-linkedin fa-lg"></i></a>
					</li>
				</ul>
			</div>
		</nav>
		<!-- End of navigation bar -->
		<div class="head_container">
			<img src="./cover_image.png" class="head_image no_blur">
			<div class="head_middle">
				<div class="head_text"><b>Hidden Markov Model</b></div>
			</div>
		</div>
		<div class="container post_body">
			<div class="row post_struct">
				<div class="col-ld-12">

					<p>In this post we will discuss the Hidden Markv Model and its implementation in Python. We will draw inspiration mainly from <a href="https://www.cs.ubc.ca/~murphyk/Bayes/rabiner.pdf" target="_blank">Lawrence R. Rabiner (1989)</a> and <a href = 'https://www.researchgate.net/publication/288957333_A_revealing_introduction_to_hidden_markov_models' target = '_blank'>Mark Stamp (2018)</a>, trying to provide an intermediate view between the more technical article by Rabiner and the more practical and educational article by Stamp. In the first half of the text we will explain the basics of HMMs in detail and establish the motivations behind our study and the second part will be dedicated to the implementation of this model in python.</p>

	 <table class="TOC">
  <tr><th>Contents</th></tr>
	<tr><td><a href="#INTRO">1. Introduction</a></td></tr>
	<tr><td><a href="#HMM">2. Hidden Markov Model</a>	</td></tr>
	<tr><td><a href="#CODE">3. Implementation</a></a></td></tr>
	</table> 
	<br></br>

					<!-- Intro -->
					<a name="INTRO"></a>
					<h2 class="section">1. Introduction</h2>
					<p>Many process in nature produce a sequence of observable outputs, such as the atmospheric variables generating different types of clouds (observations) depending on the state of the weather (a state could be a humid cold day, for example). The model that generates the clouds is $``$hidden$"$ in the sense that its not directly observable, but its output is (the clouds). The problem then consists in modeling this hidden processes not only to study how the state transitions but also to use it to predict future observations. Lets start our discussion with an example situation to motivate our study. Consider that during a stroll in the park you observe a cutted tree. Investigating it closely you see the following pattern:</p>
					<figure>
						<img src="tree.jpg" alt="tree_rings" class= "large_img">
					</figure>
					<p>You then wonder if you could use the sequence of ring sizes (observations) to model the weather transitions in the local region. Firstly lets make some simplifications and consider that each year the tree can grow a Small, Average or Large ring, and that the years can be considered only Hot or Cold (the states of the hidden process). As temperature is not the only factor that governs the growth of the tree, each observation (ring size) could be generated from both states, but with different probabilities. There are several ways of tackling this problem, but one interesting way to approach it is by considering that the weather transition only depends on the current state, not on the full sequence of states. In other words, we consider that the weather sequence is a <i>Markov</i> chain (a $``$hidden$"$ Markov chain if you like). To further discuss this model we need to first define what exactly is a Markov process and then build from it.</p>
					<p>To illustrate this discussion we will use the p5.js library to procedurally generate some images. Most images where incorporated as snapshots of a code to improve the performance of the page</p> <++>
					<div class="sketch-holder" id="c1"></div><br>
					<a name="HMM"></a><h2 class="section">2. Hidden Markov Model: Theory</h2>
					To discuss HMMs we need to first define what is a Markov process. Let $x_t$ be a random variable that depends on a parameter $t$. If $t$ represents time, then $x$ is called a <b>stochastic variable</b>. We will denote $x_t$ as a <i>state</i> and that $t$ has discrete values up to time $T$ so that we can define a sequence of events $X_T \equiv x_0, x_1, x_2, \dots, x_{T-1}$. Each state can take values from a set of $M$ possible states $x \in Q = \{q_0, q_1, \dots q_M$. The probability of a given state sequence $X$ can be written as:
					$$\begin{eqnarray}
					P(X_T) &=& (\text{Probability of state }x_0 = q_i\text{ at time }t = 0) \times (\text{Probability of }x_1 = q_j\text{ given that we where at }q_i) \times \dots\\
					 &=& P(x_0) . P(x_1 | x_0) P(x_2 | x_1, x_0) \dots P(x_{T-1} | x_{T-2}, x_{T-3}, \dots)\end{eqnarray},
					 $$</p>
					 <p>where $P(A|B)$ denotes the conditional probability of having $A$ given $B$. The probability of reaching a state $x_t$ at time $t$ is thus given by the sum of all possible paths to it ( all possible state sequences $X_{t-1}$):
					 $$
					 P(x_t)= \sum_{all\ X} P(X_{t-1}).
					 $$
					 </p>
					 <p>A <b>Markov process</b> is a sequence where the probability of a given state is fully determined <i>only</i> by the last state:
					 $$P(x_t | x_{t-1}, x_{t-2},\dots) \underset{\mathrm{Markov}}{=}  P(x_{t} | x_{t-1}).$$
					 </p>
					 <p>As $X_T$ is a temporal sequence, we can write the transition of a state $q_i$ to another $q_j$ simply as $P(q_i|q_t) \equiv a_{ij}$. The probability of obtaining a state $q_i$ is thus given by the sum of all the possible ways to reach it:
					 $$P(q_i) = \sum_j a_{ji} P(q_j)$$</p>
					 <p>If we define $A$ as a matrix with all the transition probabilities (a <b>stochastic matrix</b> as its columns add up to $1$) the equation above can be written simply as (adopting $P(x_t = q_i) \equiv P_i$)
					 $$P_{T-1}  = A P_{T-2} = A^T P_0.$$
					 </p>
					 <p>Lets apply this formalism to our motivation example. Each state $x_t$ represents a season, specifically $x_i \in \{q_0 : ``Hot",q_1 : ``Cold"\}$. The transition probability between each season allow us to write the stochastic matrix $A$:
					 $$A = \begin{pmatrix} \end{pmatrix}$$
					 </p>
					 <p>At each time $t$ the state $x_t$ generate an observation $\mathcal{o}_i \in \{``Large", ``Medium", ``Small"\}$ with probability $b_t(\mathcal{o}_i)$, thus giving the observation sequence $\mathcal{O} = \{ \mathcal{o}_0,\mathcal{o}_1, \dots \}$. The set of all possible probabilities $b_t(\mathcal{o}_j)$ defines the observation matrix $B$:
					 $$B = \begin{pmatrix} \end{pmatrix}$$
					 <!--Technical scheme-->
					 <p>If we define the initial state probability as $\pi \equiv [P(``Hot''\text{ at time }t=0), P(``Cold''\text{ at time }t=0)]$, the probability of obtaining a sequence of events $X$ and observations $\mathcal{O}$ is then given by:
					 From this formalism many results follow. The most basic is, given the model $\lambda(A, B, \pi)$, determine the probability of a string of states and observations:</p>
					 $$
					 \boxed{P(X, \mathcal{O}) = \pi_{x_o}b_{x_0}(\mathcal{o}_0)a_{x_0,x_1}b_{x_1}(\mathcal{o}_1)a_{x_1,x_2} \dots,}
					 $$
					 which can be read as: "Probability of starting at $x_0$, observing $\mathcal{o}_0$, transitioning from $x_0$ to $x_1$ etc. Beyond this, there are 3 main problems that we can solve using HMM, know very appropriately as the "3 basic problems of HMM":
					 </p>
					<a name="PROBLEMS"></a><h2 class="section">3. The 3 basic Problem's of HMM</h2>
					<h3>Problem 1 - The evaluation problem</h3>
					<p>Given the model $\lambda = (A, B, \pi)$ and the observation sequence $\mathcal{O}$, find $P(\mathcal{O}|\lambda)$.</p>
					<h3>Problem 2 - The $``$hidden$"$ problem</h3>
					<p>Given $\lambda = (A, B, \pi)$ and the observation sequence $\mathcal{O}$, find the ``optimal'' hidden sequence of events $Q$. Notice that in order to solve this problem, one must first define what ``optimal" means (there are multiple possibilities).</p>
					<h3>Problem 3 - The fit problem</h3>
					<p>Given the observation sequence $\mathcal{O}$ and the dimensions $M$ and $N$, find the model $\lambda$ that maximizes the probability of $\mathcal{O}$. This problem can be seen a training a model to a dataset.</p>
					<hr></hr>
					Now we provide not only the theoretical solution to these problems (try making a sketch of the solutions before reading then, but be advised that problems 2 and 3 are very tricky) but also algorithms to solve them efficiently.

					<h3>Solution 1</h3>
					<p>Intuitively the probability of a given sequence $\mathcal{O}$ can be obtained by summing over all possible state sequences that could generate it. Thus we must first determine the probability of a generic state sequence:
					$$P(X | \lambda) = \pi_{x_0} a_{x_0,x_1} a_{x_1, x_2} \dots$$</p>
					<p>and the probability of $\mathcal{O}$ given a sequence of events:
					$$P(\mathcal{O} | X, \lambda) = b_0(x_0) b_1(x_1) \dots$$
					</p>
					<p>Thus the probability of the observation sequence can be obtained by summing over all possible $X$s:
					$$
					P(\mathcal{O} | \lambda) = \sum_{X} P(\mathcal{O}, X | \lambda) P(X | \lambda).
					$$
					</p>
					<p>From a theoretical point of view the problem ends here. But how many operations one must do to evaluate $P(\mathcal{O} | \lambda)$ using this equation? Writing it explicitly:
					$$
					P(\mathcal{O} | \lambda) = \sum_{x_0}\sum_{x_1}\dots\sum_{x_T} \pi_{x_0}b_{x_0}(\mathcal{o}_0)a_{x_0,x_1}b_{x_1}(\mathcal{o}_1)a_{x_1,x_2} \dots.
					$$
					which yields a total of $(2T-1)N^T$ multiplications and $N^T-1$ additions. For small sequences this number of operations is unfeasible even in the most modern computers ($N=5$ and $T=100$ yields $\approx$ $10^{71}$ operations). A more efficient way of solving this can be achieved with an algorithm called <i>forward-backward procedure</i> (should ring some bells on people that have studied neural nets). It is defined as follows.</p> 
					<h4>$\alpha$ - pass: Forward procedure</h4>
					<p>Define the forward variable $\alpha$ as: 
					$$
					\alpha_t(i) \equiv P(\mathcal{o}_0, \mathcal{o}_1, \mathcal{o}_2, \dots, \mathcal{o}_t, x_t = q_i | \lambda),
					$$ which is essentially the probability of being at state $x_t = q_i$ at time $t$ and having the partial observation $\mathcal{o}_t$. We can evaluate all $\alpha$ in a recurrent manner:</p>
					<p>
					<ol>
						<li>Initialization: $$\alpha_0(i) = \pi_i b_i(\mathcal{o}_0),\hspace{1.5cm} 0 \leq i \leq N.$$</li>
						<li>Induction: $$\alpha_{t+1}(j) = \left( \sum_{i=1}^N \alpha_t(i) a_{ij} \right) b_i(\mathcal{o}_{t+1}),
							\hspace{1.5cm}\begin{array}{l}
													0 \leq t \leq T\\
													0 \leq j \leq N
													\end{array}	$$</li>
						<li>Termination $$P(\mathcal{O}, \lambda) = \sum_{i=1}^N \alpha_T(i)$$</li>
					</ol>
					With this method we only need to make $N^2 T$ multiplications, as opposed to more than $2T N^T$ for the naı̈ve approach. This step fully solves problem 1, but we will discuss the remaining part of the algorithm as it will be useful for the other problems. The <i>backward</i> procedure consists of:
					<h4>$\beta$ - pass: Backward procedure</h4>
					Define the backward variable $\beta_t(i)$ as:
					$$\beta_t(i) \equiv P(\mathcal{o}_{t+1}, \mathcal{o}_{t+2}, \mathcal{o}_2, \dots, \mathcal{o}_{T-1}| x_t = q_i, \lambda),$$
					that can be interpreted as the probability of observing the remaining partial observation sequence after state $x_t$. All backwards variables can be obtained in a recurrent manner:
					<ol>
						<li>Initialization: $$\beta_{T-1}(i) = 1$$</li>
						<li>Induction: $$\beta_{t+1}(j) \sum_{i=1}^N a_{ij} b_i(\mathcal{o}_{t+1}) \beta_{t+1}(j)
							\hspace{1.5cm}\begin{array}{l}
													0 \leq t \leq T\\
													0 \leq j \leq N
													\end{array}	$$</li>
					</ol>
					This procedure will be useful in the next solution.
					<h3>Solution 2</h3>
					<p>The objective is to find the $``$best$''$ state sequence given a model $\lambda$ and $\mathcal{O}$. As stated before, the word ``best'' can have many meanings. For example, one might want to find the states $Q$ that are individually most likely (thus minimizing the number of incorrect states). To implement this solution, we define:
					$$\gamma_t(i) = P(x_t = q_i | \mathcal{O}, \lambda),$$
					which is the probability of being at state $q_t$ at time $t$ given the observation sequence $\mathcal{O}$. This variable can be written in terms of the forward and backward variables as:
					$$\gamma_t(i) = \frac{\alpha_t(i) \beta_t(i)}{P(\mathcal{O} | \lambda)} = \frac{\alpha_t(i) \beta_t(i)}{\sum_i \alpha_t(i) \beta_t(i)}$$.</p>
					<p>From the equation above its clear that $\sum_i\gamma_t(i) = 1$. As we are seeking the most likely state at each $t$, the solution is given simply as:
					$$x_t = \underset{i}{\mathrm{argmax}}\ \gamma_t(i).$$
					</p>
					<p>The problem with this solution is that the ``best'' sequence might not be even a valid sequence (if the transition between some states is impossible). Another solution to this problem can be achieved by choosing a alternative optimality criteria, such as maximizing the number of correct state pairs, triplets, etc... The most used [2] is maximizing the probability of the whole sequence $Q$ given by $P(Q, \mathcal{O}| \lambda)$. There is a formal solution for finding this optimal solution based on Dynamic Programming called the <b>Viterbi Algorithm</b>. The interested reader is encouraged to read article [1] as its very detailed and reproducing the demonstration here would be outside the scope of this post.</p> 

					<h3>Solution 3</h3>
					<p>This is probably the most important (and difficult) problem of the bunch. Our task is, given the hyper-parameters (number of possible states $N$ and observations $M$), fit the model to the data (observation sequence $\mathcal{O})$. That is, find the model $\lambda = (A, B, \pi)$ that $P(\mathcal{O} | \lambda)$ is maximized. There is no know theoretical solution to this problem, and it is in this that HMMs really shine, as they provide a efficient way of finding a local maxima for $P(\mathcal{O} | \lambda)$ that is very similar to the EM algorithm (that is widely know in the machine learning community). The solution is as follows.</p>
					<p>Define a variable (commonly called $``$di-gamma$''$) $\gamma_t(i, j)$ as:
					$$\gamma_t(i, j) \equiv P(x_t = q_i, x_{t+1} = q_j | \mathcal{O}, \lambda),$$
					This probability can be interpreted as the probability of getting the partial observation $\mathcal{O}_t$ and arrive at state $q_t$, transitioning to the state $q_j$ and then getting the rest of the partial observation $\mathcal{o}_{t+1},\ \mathcal{o}_{t+2},\ \dots$. In terms of the forward and backward variables this can be expressed as
					$$
					\begin{eqnarray}\gamma_t(i,j) &=& \frac{\alpha_t(i) a_{ij} b_j(\mathcal{o}_{t+1})\beta_{t+1}(j)}{P(\mathcal{O} | \lambda)}\\
					&=& \frac{\alpha_t(i) a_{ij} b_j(\mathcal{o}_{t+1})\beta_{t+1}(j)}{\sum_{ij}\alpha_t(i) a_{ij} b_j(\mathcal{o}_{t+1})\beta_{t+1}(j)}
					\end{eqnarray}
					$$</p>
					<p>While $\sum_{t}\gamma_t(i)$ can be interpreted as the expected number of transitions from $q_i$ the quantity di-gmma $\sum_{t} \gamma_t(i,j)$ represents the expected number if transitions from $q_i$ to $q_t$. Both gammas are related via $\gamma_t(i) = \sum_j \gamma_t(i,j)$ Following the rationale of the EM (Expectation - Modification) algorithm, we then compute $P(\mathcal{O} | \lambda)$ in two steps. (E - step) First we find the expected value of everything and them we update the model. If it did not reached a local maxima (or a precision threshold) then we modify it (M - step). The only missing piece now is how to modify the model to achieve a updated estimation $\bar{\lambda}) = (\bar{A}, \bar{B}, \bar{\pi})$, which can be done with the following equations:</p>
					<p>
					$$
					\begin{eqnarray}
					\bar{\pi}_i &=& \text{Expected frequency of state }q_i\text{ at time 0},\\
					&=& \gamma_0(i).\\ \,\\
					\bar{a}_{ij} &=& \frac{\text{Expected transitions from }q_i\text{ to }q_j}{\text{Expected transitions from }q_i},\\
					&=& \frac{\sum_t \gamma_t(i, j)}{\sum_t \gamma_t(i)}.\\ \,\\
					\bar{b}_i(k) &=& \frac{\text{Expected number of times in state }q_i\text{ and observing }\mathcal{o}_k}{\text{Expected number of times in state }q_i},\\
					&=& \frac{\sum_t \gamma_t(i)}{\sum_t \gamma_t(i)}.
					\end{eqnarray}
					$$</p>
					<p>The procedure to solve problem 3 is then given by the following steps:
					<ol>
						<li>(Initialization step) Initialize $\lambda = (A, B, \pi)$ randomly.</li>
						<li>(Expetation step) Compute $\alpha_t(i)$, $\beta_t(i)$, $\gamma_t(i,j)$ and $\gamma_t(i)$ for all $i$ and $t$;</li>
						<li>(Modification step) Re-estimate $\bar{\lambda} = (\bar{A}, \bar{B}, \bar{\pi})$;</li>
						<li>(Ecaluation step) If $P(\mathcal{O} | \bar{\lambda}) > P(\mathcal{O} | \lambda)$, goto 2. Else terminate and return $\bar{\lambda}$.</li>
					</p>
					<h4>Scale</h4>
					As all calculations involve multiplications of really small probabilities (as the number of possible combinations of states and observations is huge), the variables have a serious tendency to underflow. To solve this, we can the scale the variables. Consider the calculation for the forward variable:
					$$\alpha_t(i) = \sum_j \alpha_{t-1}(j) a_{ij} b_i(\mathcal{o}_t),$$
					whose interpratiation is the probability of observing $\mathcal{O}t$ and reaching state $q_t$. A normalization idea is to normalize this quantity by the sum of all $\alpha_t(j)$ (over $j$). Ideed, it can be shown (see [1]) that this scale does not interfere in the solution and avoids underflow. Thus we define the <i>scale term</i>:
					$$c_t \equiv \frac{1}{\sum_j \alpha_t(j)},$$
					All variables ($\alpha$, $\beta$ and $\gamma$'s) can then multiplied by this term to avoid underflow. Another nice property is that the probability $P(\mathcal{O} | \lambda)$ can be directly obtained via this scale term:
					$$\log P(\mathcal{O} | \lambda) = - \sum_{j=0}^{T-1} \log c_j.$$
					<h4>Model selection</h4>
					The algorithm we discussed is capable of finding a local maxima for $P(\mathcal{O} | \lambda)$, but is the solution unique? Suppose we have two models, $\lambda_1$, and $\lambda_2$, with:
					$$
					\begin{eqnarray}
					A_1 &=& \begin{pmatrix} p & 1-p \\ 1-p & p \end{pmatrix} \hspace{1cm} B_1 = \begin{pmatrix} q & 1-q \\ 1-q & q \end{pmatrix}, \\  
					A_2 &=& \begin{pmatrix} r & 1-r \\ 1-r & r \end{pmatrix} \hspace{1cm} B_2 = \begin{pmatrix} s & 1-s \\ 1-s & s \end{pmatrix},
					\end{eqnarray}
					$$
					where $\pi_1 = \pi_2 = [0.5, 0.5]$. Both models could be considered equivalent if the expected value of all observations in $\mathcal{O}$ are individually equal in both models. If we assume arbitrarily (the same values reference [1] used) $p = 0.6$, $q = 0.7$ and $r = 0.2$ then we would get:
					$$
					\begin{eqnarray}
					&\,& A_1 B1 = A_2 B_2 \\
					&\,& \Rightarrow pq + (1 - q)(1 - p) = rs + (1 - r)(1-s)\\
					&\,& \therefore s = \frac{p + q - 2pq}{1 - 2r} \approx 0.43.
					\end{eqnarray}
					$$
					We conclude that these two wildly different models could be considered equivalent! Now an interesting question can be made: how could one measure the similarity between two models? Information theory provides us with a quantity called <b>relative entropy</b> (also know as Kullbak-Leibler divergence or information gain in machine learning contexts) that fits this role nicely and can be expressed as
					$$
					D(\lambda_1, \lambda_2) = P(\mathcal{O}^{(2)}  | \lambda_1) \log \left( \frac{P(\mathcal{O}^{(2)}  | \lambda_1)}{P(\mathcal{O}^{(2)}  | \lambda_1)} \right),
					$$
					where $\mathcal{O}^{(2)}$ is a observation sequence obtained from $\lambda_2$. With this we now can not only measure the distance of a trained model from the true one (when available) or from the random start. We could also measure how different solutions differ from each other.
					<h4>Further topics and variations</h4>
					There are several variants to the HMM. Many of then are discussed in depth in reference [1] and are very interesting such as HMM with absorbing states (breaking the engodicidy of the model) and HMM with continuous values. As interesting these topics are, we refrain from discussing then to reduce the scope of this post, but I felt that it was important to say that this model can be taken further and is a very interesting topic to study :D. Now we shall focus on how to implement this model in python, as most sources only provide pseudo code for the implementation.

					<a name="CODE"></a><h2 class="section">3. Implementation</h2>
					{% include 'weather.html' %}
				</div>
			</div>
		</div>

		<hr/>
		<script src="../../js/script.js"> </script><!--TARGET-->
		<!-- Bootstrap + JQuery -->
		<script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
		<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
		<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>

		<script src="https://kit.fontawesome.com/9ead9d8df4.js" crossorigin="anonymous"></script>



	</body>
</html>
